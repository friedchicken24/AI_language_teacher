import streamlit as st
import google.generativeai as genai
import assemblyai as aai
import os
from gtts import gTTS
import uuid
from io import BytesIO
import librosa
import numpy as np
import soundfile as sf

# --- C·∫§U H√åNH BAN ƒê·∫¶U ---
st.set_page_config(page_title="Tr·ª£ l√Ω ·∫£o", page_icon="ü§ñ", layout="wide")
st.title("ü§ñ Tr·ª£ L√Ω ·∫¢o Th√¥ng Minh")

# --- C·∫§U H√åNH API KEYS ---
try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
    aai.settings.api_key = st.secrets["ASSEMBLYAI_API_KEY"]
except KeyError as e:
    st.error(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y API Key: {e}. Vui l√≤ng ki·ªÉm tra l·∫°i m·ª•c 'Secrets'.")
    st.stop()

# --- C√ÅC H√ÄM TI·ªÜN √çCH ---
def text_to_speech(text, lang='vi'):
    try:
        tts = gTTS(text=text, lang=lang, slow=False)
        filename = f"response_{uuid.uuid4()}.mp3"
        tts.save(filename)
        return filename
    except Exception as e:
        st.error(f"L·ªói khi t·∫°o gi·ªçng n√≥i: {e}")
        return None

def speech_to_text(wav_bytes):
    try:
        config = aai.TranscriptionConfig(language_code="vi")
        transcriber = aai.Transcriber(config=config)
        transcript = transcriber.transcribe(wav_bytes)

        if transcript.status == aai.TranscriptStatus.error:
            st.error(f"L·ªói t·ª´ AssemblyAI: {transcript.error}")
            return None
        return transcript.text
    except Exception as e:
        st.error(f"L·ªói khi nh·∫≠n di·ªán gi·ªçng n√≥i qua AssemblyAI: {e}")
        return None

def get_ai_response(user_text, conversation_history, system_prompt):
    model = genai.GenerativeModel('gemini-1.5-flash-latest')
    messages = [{"role": "system", "content": system_prompt}]
    gemini_history = []
    for entry in conversation_history:
        role = 'model' if entry['role'] == 'assistant' else entry['role']
        gemini_history.append({'role': role, 'parts': [entry['content']]})
    chat = model.start_chat(history=gemini_history)
    try:
        response = chat.send_message(user_text)
        return response.text
    except Exception as e:
        st.error(f"L·ªói khi g·ªçi Gemini: {e}")
        return "T√¥i xin l·ªói, t√¥i ƒëang g·∫∑p s·ª± c·ªë v·ªõi b·ªô n√£o c·ªßa m√¨nh."

# --- GIAO DI·ªÜN ---
with st.sidebar:
    st.title("T√πy Ch·ªçn Tr·ª£ L√Ω ·∫¢o")
    personas = {
        "Tr·ª£ l√Ω th√¢n thi·ªán": "B·∫°n l√† m·ªôt tr·ª£ l√Ω ·∫£o t√™n l√† Zen...",
        "Nh√† s·ª≠ h·ªçc uy√™n b√°c": "B·∫°n l√† m·ªôt nh√† s·ª≠ h·ªçc uy√™n b√°c...",
        "Chuy√™n gia c√¥ng ngh·ªá": "B·∫°n l√† m·ªôt chuy√™n gia c√¥ng ngh·ªá h√†ng ƒë·∫ßu..."
    }
    selected_persona_name = st.selectbox("Ch·ªçn vai tr√≤:", options=list(personas.keys()))
    system_prompt = personas[selected_persona_name]

# Kh·ªüi t·∫°o session state
if "conversation" not in st.session_state:
    st.session_state.conversation = []
if "last_response_audio" not in st.session_state:
    st.session_state.last_response_audio = None

# Hi·ªÉn th·ªã l·ªãch s·ª≠ tr√≤ chuy·ªán
chat_container = st.container(height=400)
with chat_container:
    for entry in st.session_state.conversation:
        with st.chat_message(entry["role"]):
            st.write(entry["content"])

# T·ª± ƒë·ªông ph√°t √¢m thanh
if st.session_state.last_response_audio:
    st.audio(st.session_state.last_response_audio, autoplay=True)
    if os.path.exists(st.session_state.last_response_audio):
        os.remove(st.session_state.last_response_audio)
    st.session_state.last_response_audio = None

# --- KHU V·ª∞C T·∫¢I FILE L√äN ---
st.divider()
st.subheader("Tr√≤ chuy·ªán v·ªõi AI")
st.write("Ghi √¢m m·ªôt c√¢u h·ªèi b·∫±ng ƒëi·ªán tho·∫°i ho·∫∑c m√°y t√≠nh, sau ƒë√≥ t·∫£i file l√™n ƒë√¢y.")

uploaded_file = st.file_uploader("T·∫£i file √¢m thanh c·ªßa b·∫°n (MP3, WAV, M4A)...", type=['mp3', 'wav', 'm4a'])

if uploaded_file is not None:
    st.audio(uploaded_file, format='audio/wav')
    
    if st.button("G·ª≠i √¢m thanh ƒë·ªÉ AI x·ª≠ l√Ω"):
        with st.spinner("ƒêang x·ª≠ l√Ω √¢m thanh c·ªßa b·∫°n..."):
            # ƒê·ªçc file ng∆∞·ªùi d√πng t·∫£i l√™n
            audio_bytes = uploaded_file.getvalue()
            
            # L∆∞u v√†o b·ªô nh·ªõ ƒë·ªÉ librosa ƒë·ªçc
            audio_buffer = BytesIO(audio_bytes)
            
            # Resample √¢m thanh v·ªÅ 16kHz
            y, sr = librosa.load(audio_buffer, sr=None)
            target_sr = 16000
            if sr != target_sr:
                y = librosa.resample(y=y, orig_sr=sr, target_sr=target_sr)
            
            # Chuy·ªÉn ƒë·ªïi l·∫°i th√†nh bytes ƒë·ªãnh d·∫°ng WAV
            wav_processed_buffer = BytesIO()
            sf.write(wav_processed_buffer, y, target_sr, format='WAV', subtype='PCM_16')
            wav_bytes_processed = wav_processed_buffer.getvalue()

        # ---- B·∫ÆT ƒê·∫¶U LU·ªíNG X·ª¨ L√ù ----
        with st.spinner("AI ƒëang l·∫Øng nghe..."):
            user_text = speech_to_text(wav_bytes_processed)

        if user_text:
            st.session_state.conversation.append({"role": "user", "content": user_text})
            with st.spinner("AI ƒëang suy nghƒ©..."):
                ai_response_text = get_ai_response(user_text, st.session_state.conversation, system_prompt)
            st.session_state.conversation.append({"role": "assistant", "content": ai_response_text})
            with st.spinner("AI ƒëang chu·∫©n b·ªã n√≥i..."):
                audio_file = text_to_speech(ai_response_text)
            if audio_file:
                st.session_state.last_response_audio = audio_file
            st.rerun()
        else:
            st.error("Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c gi·ªçng n√≥i. H√£y th·ª≠ ghi √¢m l·∫°i r√µ h∆°n.")
